{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 01:29:58.558631: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-04 01:29:58.614605: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-04 01:29:59.397408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated_data = pd.read_csv('../data/comsolidated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'time_in_seconds', 'frame', 'total_movement_per_second',\n",
       "       'pose_openness', 'leaning', 'head_horizontal', 'head_vertical',\n",
       "       'left_arm_angle', 'left_arm_v_movement', 'left_arm_h_movement',\n",
       "       'right_arm_angle', 'right_arm_v_movement', 'right_arm_h_movement',\n",
       "       'left_hand_orientation', 'left_hand_state', 'right_hand_orientation',\n",
       "       'right_hand_state', 'video_name', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with empty value \n",
    "\n",
    "# drop left_arm_v_movement and right_arm_v_movement, due to ~10% empty value \n",
    "data_dropped = consolidated_data.drop(columns=['left_arm_v_movement', 'right_arm_v_movement'])\n",
    "# Deal with empty value\n",
    "data_filled = data_dropped.copy()\n",
    "mask = data_filled['video_name'].shift() == data_filled['video_name']\n",
    "data_filled.loc[mask] = data_filled.loc[mask].fillna(method='ffill')\n",
    "# Drop rows with null values inside\n",
    "data_filled = data_filled.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering \n",
    "data_encoded = data_filled.copy()\n",
    "# Calculate body symmetry feature\n",
    "# data_encoded['arm_angle_symmetry'] = data_encoded['left_arm_angle'] - data_encoded['right_arm_angle']\n",
    "# data_encoded['arm_h_movement_symmetry'] = np.where(data_encoded['left_arm_h_movement'] == data_encoded['right_arm_h_movement'], 1, 0)\n",
    "# data_encoded['hand_orientation_symmetry'] = np.where(data_encoded['left_hand_orientation'] == data_encoded['right_hand_orientation'], 1, 0)\n",
    "# data_encoded['hand_state_symmetry'] = np.where(data_encoded['left_hand_state'] == data_encoded['right_hand_state'], 1, 0)\n",
    "# data_encoded['total_movement_change'] = data_encoded['total_movement_per_second'].diff(periods=window_size)\n",
    "# Drop rows with NaN values resulting from the temporal changes calculation\n",
    "# data_encoded.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the high correlated columns \n",
    "dropped_cols = [\n",
    "                'left_hand_state',\n",
    "                'right_hand_state'\n",
    "                ]\n",
    "data_dropped = data_encoded.drop(columns=dropped_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding \n",
    "categorical_cols = ['leaning',\n",
    "                    'head_horizontal', \n",
    "                    'head_vertical', \n",
    "                    'left_arm_h_movement',\n",
    "                    'right_arm_h_movement',\n",
    "                    'left_hand_orientation',\n",
    "                    'right_hand_orientation'\n",
    "                    ]\n",
    "# Apply one-hot encoding to the selected categorical columns\n",
    "data_one_hot = pd.get_dummies(data_dropped, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicate columns\n",
    "dup_cols = ['leaning_Backward',\n",
    "            'head_horizontal_STILL',\n",
    "            'head_vertical_STILL',\n",
    "            'left_arm_h_movement_CALCULATING',\n",
    "            'right_arm_h_movement_CALCULATING']\n",
    "data_processed = data_one_hot.drop(columns=dup_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling \n",
    "numerical_cols = ['total_movement_per_second', 'pose_openness']\n",
    "# Apply normalization scaling to the selected numerical columns\n",
    "scaler = MinMaxScaler()\n",
    "data_processed[numerical_cols] = scaler.fit_transform(data_processed[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1235988/2507056664.py:2: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  grouped = data_processed.groupby('video_name').apply(lambda x: x.sort_values('time_in_seconds'))\n",
      "/tmp/ipykernel_1235988/2507056664.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  X_video = X[consolidated_data['video_name'] == video_name]\n"
     ]
    }
   ],
   "source": [
    "# Group the data by 'video_name' and sort within each group by 'time_in_seconds'\n",
    "grouped = data_processed.groupby('video_name').apply(lambda x: x.sort_values('time_in_seconds'))\n",
    "\n",
    "# Drop 'Unnamed: 0', 'video_name', 'time_in_seconds' columns\n",
    "grouped = grouped.drop(['Unnamed: 0', 'video_name', 'time_in_seconds', 'frame'], axis=1)\n",
    "\n",
    "# Define features and labels\n",
    "X = grouped.drop('label', axis=1)\n",
    "Y = grouped['label']\n",
    "# video_name = grouped['video_name']\n",
    "\n",
    "def reshape_inputs(X, Y, video_names):\n",
    "    X_reshaped = []\n",
    "    Y_reshaped = []\n",
    "    \n",
    "    for video_name in video_names:\n",
    "        # Get all data points for this video\n",
    "        X_video = X[consolidated_data['video_name'] == video_name]\n",
    "        Y_video = Y[consolidated_data['video_name'] == video_name]\n",
    "        \n",
    "        # Append to the reshaped data (note that this converts the dataframes to numpy arrays)\n",
    "        X_reshaped.append(X_video.values)\n",
    "        Y_reshaped.append(Y_video.values[0])  # The label is the same for all data points in a video\n",
    "        \n",
    "    X_reshaped = pad_sequences(X_reshaped, dtype='float32', padding='post')\n",
    "    Y_reshaped = np.array(Y_reshaped)\n",
    "\n",
    "    return np.array(X_reshaped), np.array(Y_reshaped)\n",
    "\n",
    "X_reshaped, Y_reshaped = reshape_inputs(X, Y, consolidated_data['video_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_reshaped, Y_reshaped, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "# Define number of features and number of classes\n",
    "num_features = X_train.shape[2]  # The number of features in your input data\n",
    "num_classes = len(np.unique(Y_train))  # The number of unique classes in your labels\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(5, activation='relu', return_sequences=True, input_shape=(None, num_features)))\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(LSTM(5, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.8385 - accuracy: 0.4348 - val_loss: 0.7936 - val_accuracy: 0.3333\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 2.5400 - accuracy: 0.5217 - val_loss: 0.7969 - val_accuracy: 0.3333\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.7494 - accuracy: 0.4783 - val_loss: 0.7992 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=3, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6172 - accuracy: 0.7500\n",
      "Test loss: 0.6171596646308899, Test accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.96874394e-02, 2.29535084e-02, 7.26223907e+01, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [2.26624031e-03, 2.35831365e-02, 7.40611496e+01, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        [2.79644690e-03, 2.42782421e-02, 7.51529770e+01, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [9.30130109e-03, 2.41324473e-02, 4.06462002e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        [1.40012186e-02, 4.70497385e-02, 4.81131096e+01, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[2.38235727e-01, 3.78290899e-02, 1.56198120e+02, ...,\n",
       "         0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "        [8.99194777e-02, 2.54510604e-02, 1.69186630e+02, ...,\n",
       "         0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "        [3.53386365e-02, 2.13067085e-02, 1.69570175e+02, ...,\n",
       "         0.00000000e+00, 1.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[1.04792513e-01, 6.47176355e-02, 4.79510269e+01, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        [4.99330945e-02, 5.96468002e-02, 3.24156532e+01, ...,\n",
       "         1.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [3.61768194e-02, 6.28183782e-02, 2.97652969e+01, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[5.90189733e-02, 1.81456488e-02, 9.27082443e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [5.01430314e-03, 1.78275593e-02, 9.06938267e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.44052820e-03, 1.90017559e-02, 9.87437057e+01, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[2.95110624e-02, 1.20767336e-02, 1.05227333e+02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        [7.04891235e-03, 1.04982611e-02, 7.58935776e+01, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        [5.22834994e-03, 1.08141424e-02, 1.13914345e+02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[3.56771122e-03, 2.12082881e-02, 1.10602013e+02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [3.05552385e-03, 2.06118766e-02, 1.10777870e+02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 1.00000000e+00],\n",
       "        [2.62269983e-03, 2.07202192e-02, 1.10831947e+02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
