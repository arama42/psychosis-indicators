{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.spatial import ConvexHull\n",
    "import math\n",
    "import csv\n",
    "\n",
    "import moviepy.editor as m_editor\n",
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "# init mediapipe parameters \n",
    "\n",
    "# Function to extract subclip from original video based on start_time and end_time in seconds\n",
    "def extract_subclip(input, output, start_time, end_time):\n",
    "  original_video = m_editor.VideoFileClip(input)\n",
    "  cut_video = original_video.subclip(start_time, end_time)\n",
    "  cut_video.write_videofile(output, codec=\"libx264\")\n",
    "\n",
    "# Function to calculate the Euclidean distance between two points\n",
    "def euclidean_distance(p1, p2):\n",
    "    return np.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2)\n",
    "\n",
    "# Function to calculate the openness of a pose\n",
    "def pose_openness(holistic_landmarks, image, mp_holistic):\n",
    "    image_h, image_w, _ = image.shape\n",
    "    main_keypoints = [\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER],\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER],\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_HIP],\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_HIP],\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_WRIST],\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_WRIST],\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_ELBOW],\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_ELBOW],\n",
    "    ]\n",
    "    core_keypoints = [\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER],\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER],\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_HIP],\n",
    "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_HIP],\n",
    "    ]\n",
    "    \n",
    "    # coords = np.array([(kp.x, kp.y) for kp in keypoints])\n",
    "    coords = np.array([(int(kp.x * image_w), int(kp.y * image_h)) for kp in main_keypoints])\n",
    "    hull = ConvexHull(coords)\n",
    "\n",
    "    core_coords = np.array([(int(kp.x * image_w), int(kp.y * image_h)) for kp in core_keypoints])\n",
    "    core_hull = ConvexHull(core_coords)\n",
    "    \n",
    "    return hull.volume / core_hull.volume\n",
    "\n",
    "# Function to calculate leaning direction\n",
    "def leaning_direction(holistic_landmarks, mp_holistic):\n",
    "    nose = holistic_landmarks.landmark[mp_holistic.PoseLandmark.NOSE]\n",
    "    left_hip = holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_HIP]\n",
    "    right_hip = holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_HIP]\n",
    "    \n",
    "    avg_hip_z = (left_hip.z + right_hip.z) / 2\n",
    "\n",
    "    if nose.z < avg_hip_z:\n",
    "        return \"Backward\"\n",
    "    else:\n",
    "        return \"Forward\"\n",
    "\n",
    "# Function to calculate head direction\n",
    "def head_direction(prev, curr, image, mp_holistic):\n",
    "    image_h, image_w, _ = image.shape\n",
    "    curr_nose = curr.landmark[mp_holistic.PoseLandmark.NOSE] \n",
    "    prev_nose = prev.landmark[mp_holistic.PoseLandmark.NOSE]\n",
    "\n",
    "    curr_nose_cood = np.array([int(curr_nose.x * image_w), int(curr_nose.y * image_h)])\n",
    "    prev_nose_cood = np.array([int(prev_nose.x * image_w), int(prev_nose.y * image_h)])\n",
    "    nose_diff = curr_nose_cood - prev_nose_cood\n",
    "    horizontal = 'STILL'\n",
    "    vertical = 'STILL'\n",
    "    if nose_diff[0] > 0:\n",
    "        horizontal = \"RIGHT\"\n",
    "    elif nose_diff[0] < 0:\n",
    "        horizontal = 'LEFT'\n",
    "    \n",
    "    if nose_diff[1] > 0:\n",
    "        vertical = 'UP'\n",
    "    elif nose_diff[1] < 0:\n",
    "        vertical = 'DOWN'\n",
    "    return horizontal, vertical\n",
    "\n",
    "# Function to calculate angle between three landmarks\n",
    "def calculate_angle(l1, l2, l3):\n",
    "\n",
    "    # Calculate the angle between the three points\n",
    "    angle = math.degrees(math.atan2(l3.y - l2.y, l3.x - l2.x) - math.atan2(l1.y - l2.y, l1.x - l2.x))\n",
    "    \n",
    "    # Check if the angle is less than zero.\n",
    "    if angle < 0:\n",
    "        # Add 360 to the found angle.\n",
    "        angle += 360\n",
    "  \n",
    "    return angle\n",
    "\n",
    "# Function to calculate angle between three landmarks using numpy module\n",
    "def numpy_angle(l1,l2,l3, width, height):\n",
    "    a = np.array([l1.x * width, l1.y * height])\n",
    "    b = np.array([l2.x * width, l2.y * height])\n",
    "    c = np.array([l3.x * width, l3.y * height])\n",
    "\n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "\n",
    "    return np.degrees(angle)\n",
    "\n",
    "# Function to calculate hand orientation\n",
    "def orientation(l0, l9): \n",
    "    x0 = l0.x\n",
    "    y0 = l0.y\n",
    "    \n",
    "    x9 = l9.x\n",
    "    y9 = l9.y\n",
    "    \n",
    "    if abs(x9 - x0) < 0.05:      # since tan(0) --> âˆž\n",
    "        m = 1000000000\n",
    "    else:\n",
    "        m = abs((y9 - y0)/(x9 - x0))       \n",
    "        \n",
    "    if m>=0 and m<=1:\n",
    "        if x9 > x0:\n",
    "            return \"Right\"\n",
    "        else:\n",
    "            return \"Left\"\n",
    "    if m>1:\n",
    "        if y9 < y0:       # since, y decreases upwards\n",
    "            return \"Up\"\n",
    "        else:\n",
    "            return \"Down\"\n",
    "\n",
    "def process_video(video_cut, video_out, output_csv, mp_drawing, mp_holistic, mp_face_mesh, holistic, face_mesh):\n",
    "    cap = cv2.VideoCapture(video_cut)\n",
    "\n",
    "    # Get the video dimensions and FPS(input)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Initialize the VideoWriter(output)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # You can also use \"XVID\" or \"MJPG\" for AVI files\n",
    "    out = cv2.VideoWriter(video_out, fourcc, fps, (width, height))\n",
    "\n",
    "    PL = mp_holistic.PoseLandmark\n",
    "    HL = mp_holistic.HandLandmark\n",
    "\n",
    "    ## Holistic\n",
    "    prev_landmarks = None\n",
    "    total_movement = 0\n",
    "    frame_movement = 0\n",
    "    openness_value = 0\n",
    "    head_horizontal = \"\"\n",
    "    head_vertical = \"\"\n",
    "    holistic_threshold = 0.001  # Adjust the threshold to fine-tune movement detection sensitivity\n",
    "    holistic_keypoints = [\n",
    "        mp_holistic.PoseLandmark.LEFT_WRIST,\n",
    "        mp_holistic.PoseLandmark.RIGHT_WRIST,\n",
    "        mp_holistic.PoseLandmark.LEFT_ANKLE,\n",
    "        mp_holistic.PoseLandmark.RIGHT_ANKLE,\n",
    "    ]\n",
    "\n",
    "    ## Arms\n",
    "    left_arm_movement = 0\n",
    "    right_arm_movement = 0\n",
    "\n",
    "    la_counter = 0 \n",
    "    la_vert = None\n",
    "    la_leaning = None\n",
    "\n",
    "    ra_counter = 0 \n",
    "    ra_vert = None\n",
    "    ra_leaning = None\n",
    "\n",
    "    ## Hand\n",
    "    lh_stage = None\n",
    "    lh_tip_distance = 0\n",
    "    lh_orientation = None\n",
    "\n",
    "    rh_stage = None\n",
    "    rh_tip_distance = 0\n",
    "    rh_orientation = None\n",
    "\n",
    "    # open output CSV file and add header row\n",
    "    with open(output_csv, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['time_in_seconds', \n",
    "                        'frame', \n",
    "                        'total_movement_per_second', \n",
    "                        'pose_openness', \n",
    "                        'leaning', \n",
    "                        'head_horizontal',\n",
    "                        'head_vertical',\n",
    "                        'left_arm_angle', \n",
    "                        'left_arm_v_movement', \n",
    "                        'left_arm_h_movement',\n",
    "                        'right_arm_angle', \n",
    "                        'right_arm_v_movement', \n",
    "                        'right_arm_h_movement', \n",
    "                        'left_hand_orientation', \n",
    "                        'left_hand_state', \n",
    "                        'right_hand_orientation', \n",
    "                        'right_hand_state'])\n",
    "\n",
    "        # Process the video frames\n",
    "        frame_number = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "        \n",
    "            # Convert the frame to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Process the frame with MediaPipe's Holistic module\n",
    "            results = holistic.process(frame_rgb)\n",
    "\n",
    "            # Draw holistic landmarks on the frame\n",
    "            if results.pose_landmarks:\n",
    "                current = results.pose_landmarks\n",
    "                current_lh = results.left_hand_landmarks\n",
    "                current_rh = results.right_hand_landmarks\n",
    "\n",
    "                mp_drawing.draw_landmarks(frame, current, mp_holistic.POSE_CONNECTIONS)\n",
    "                mp_drawing.draw_landmarks(frame, current_lh, mp_holistic.HAND_CONNECTIONS)\n",
    "                mp_drawing.draw_landmarks(frame, current_rh, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "                ## Holistic movements\n",
    "                # Calculate the total movement\n",
    "                if prev_landmarks:\n",
    "                    frame_movement = 0\n",
    "                    for kp in holistic_keypoints:\n",
    "                        distance = euclidean_distance(results.pose_landmarks.landmark[kp], prev_landmarks.landmark[kp])\n",
    "                        frame_movement += distance\n",
    "                    if frame_movement > holistic_threshold:\n",
    "                        total_movement += frame_movement\n",
    "                    \n",
    "                    head_horizontal, head_vertical = head_direction(prev_landmarks, current, frame_rgb, mp_holistic)\n",
    "            \n",
    "                # Calculate and display the total movement and pose openness on the frame\n",
    "                openness_value = pose_openness(results.pose_landmarks, frame_rgb, mp_holistic)\n",
    "                # Calculate and display the leaning direction\n",
    "                leaning_dir = leaning_direction(results.pose_landmarks, mp_holistic)\n",
    "\n",
    "                ## Hand movements\n",
    "                # distance b/w INDEX_FINGER_TIP and THUMB_TIP\n",
    "                if current_lh:\n",
    "                    lh_tip_distance = euclidean_distance(current_lh.landmark[HL.INDEX_FINGER_TIP],current_lh.landmark[HL.THUMB_TIP])\n",
    "                    if current_lh.landmark[HL.MIDDLE_FINGER_TIP].y < current_lh.landmark[HL.MIDDLE_FINGER_MCP].y and current_lh.landmark[HL.RING_FINGER_TIP].y < current_lh.landmark[HL.RING_FINGER_MCP].y \\\n",
    "                        and current_lh.landmark[HL.PINKY_TIP].y < current_lh.landmark[HL.PINKY_TIP].y and lh_tip_distance < 0.015:\n",
    "                        lh_stage = 'CLOSED'\n",
    "                    else:\n",
    "                        lh_stage = 'OPEN'\n",
    "                        lh_orientation = orientation(current_lh.landmark[HL.WRIST], current_lh.landmark[HL.MIDDLE_FINGER_MCP])\n",
    "\n",
    "                if current_rh:\n",
    "                    rh_tip_distance = euclidean_distance(current_rh.landmark[HL.INDEX_FINGER_TIP],current_rh.landmark[HL.THUMB_TIP])\n",
    "                    if current_rh.landmark[HL.MIDDLE_FINGER_TIP].y < current_rh.landmark[HL.MIDDLE_FINGER_MCP].y and current_rh.landmark[HL.RING_FINGER_TIP].y < current_rh.landmark[HL.RING_FINGER_MCP].y \\\n",
    "                        and current_rh.landmark[HL.PINKY_TIP].y < current_rh.landmark[HL.PINKY_TIP].y and rh_tip_distance < 0.015:\n",
    "                        rh_stage = 'CLOSED'\n",
    "                    else:\n",
    "                        rh_stage = 'OPEN'\n",
    "                        rh_orientation = orientation(current_rh.landmark[HL.WRIST], current_rh.landmark[HL.MIDDLE_FINGER_MCP])\n",
    "\n",
    "                ## Arm movements\n",
    "                # Calculate weather arm is up or down\n",
    "                la_angle = numpy_angle(current.landmark[PL.LEFT_WRIST], current.landmark[PL.LEFT_ELBOW], current.landmark[PL.LEFT_SHOULDER], width, height)\n",
    "                ra_angle = numpy_angle(current.landmark[PL.RIGHT_WRIST], current.landmark[PL.RIGHT_ELBOW], current.landmark[PL.RIGHT_SHOULDER], width, height)\n",
    "\n",
    "                if la_angle > 160:\n",
    "                    la_vert = \"DOWN\"\n",
    "                if la_angle < 30 and la_vert =='DOWN':\n",
    "                    la_vert=\"UP\"\n",
    "                    la_counter +=1\n",
    "\n",
    "                if ra_angle > 160:\n",
    "                    ra_vert = \"DOWN\"\n",
    "                if ra_angle < 30 and ra_vert =='DOWN':\n",
    "                    ra_vert=\"UP\"\n",
    "                    ra_counter +=1\n",
    "\n",
    "                # Calculate wheather arm is leaning forward\n",
    "                if abs(current.landmark[PL.RIGHT_WRIST].z) > abs(current.landmark[PL.RIGHT_ELBOW].z):\n",
    "                    ra_leaning = 'FORWARD'\n",
    "                else:\n",
    "                    ra_leaning = 'NOT FORWARD'\n",
    "\n",
    "                if abs(current.landmark[PL.LEFT_WRIST].z) > abs(current.landmark[PL.LEFT_ELBOW].z) :\n",
    "                    la_leaning = 'FORWARD'\n",
    "                else:\n",
    "                    la_leaning = 'NOT FORWARD'\n",
    "\n",
    "                # write to output video\n",
    "                l1 = current.landmark[PL.LEFT_SHOULDER]\n",
    "                l2 = current.landmark[PL.LEFT_ELBOW]\n",
    "                l3 = current.landmark[PL.LEFT_WRIST]\n",
    "                r1 = current.landmark[PL.RIGHT_SHOULDER]\n",
    "                r2 = current.landmark[PL.RIGHT_ELBOW]\n",
    "                r3 = current.landmark[PL.RIGHT_WRIST]\n",
    "                \n",
    "                cv2.putText(frame, f\"Left shoulder:({round(l1.x,2)}, {round(l1.y,2)}, {round(l1.z,2)}) elbow:({round(l2.x,2)}, {round(l2.y,2)}, {round(l2.z,2)}) wrist: ({round(l3.x,2)}, {round(l3.y,2)}, {round(l3.z,2)})\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"Left arm: {la_vert}  {la_leaning}\", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"Left arm angle: {la_angle:.2f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"Right shoulder:({round(r1.x,2)}, {round(r1.y,2)}, {round(r1.z,2)}) elbow:({round(r2.x,2)}, {round(r2.y,2)}, {round(r2.z,2)}) wrist: ({round(r3.x,2)}, {round(r3.y,2)}, {round(r3.z,2)})\", (10,120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"Right arm: {ra_vert}  {ra_leaning}\", (10,150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"Right arm angle: {ra_angle:.4f}\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"Left Hand: {lh_tip_distance} {lh_stage} {lh_orientation}\", (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "                cv2.putText(frame, f\"Right Hand: {rh_tip_distance} {rh_stage} {rh_orientation}\", (10, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"Total Movement Per Second: {total_movement:.2f}\", (10, 270), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Openness: {openness_value:.2f}\", (10, 300), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "                cv2.putText(frame, f\"Leaning: {leaning_dir}\", (10, 330), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "                cv2.putText(frame, f\"Head Horizontal: {head_horizontal}\", (10, 360), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "                cv2.putText(frame, f\"Head Vertical: {head_vertical}\", (10, 390), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "                \n",
    "                # update variables\n",
    "                prev_landmarks = results.pose_landmarks\n",
    "                frame_number += 1\n",
    "\n",
    "                time_in_seconds = frame_number / fps  \n",
    "                # Write to CSV file\n",
    "                if frame_number % fps == 0:\n",
    "                    writer.writerow([time_in_seconds, \n",
    "                                    frame_number, \n",
    "                                    total_movement, \n",
    "                                    openness_value, \n",
    "                                    leaning_dir, \n",
    "                                    head_horizontal,\n",
    "                                    head_vertical,\n",
    "                                    la_angle, \n",
    "                                    la_vert, \n",
    "                                    la_leaning, \n",
    "                                    ra_angle, \n",
    "                                    ra_vert, \n",
    "                                    ra_leaning, \n",
    "                                    lh_orientation, \n",
    "                                    lh_stage, \n",
    "                                    rh_orientation, \n",
    "                                    rh_stage])\n",
    "                    total_movement = 0 \n",
    "                    frame_movement = 0\n",
    "\n",
    "            # Save the frame\n",
    "            out.write(frame)\n",
    "\n",
    "        out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11002post-cut.mp4\n",
      "11007pt1-cut-5min.mp4\n",
      "11007pt2-cut-5min.mp4\n",
      "11007pt3-cut-5min.mp4\n",
      "11008.1-cut-5min.mp4\n",
      "11008.2-cut-5min.mp4\n",
      "3005 12m clin-cut-5min.mp4\n",
      "3005 12m clin2-cut-5min.mp4\n",
      "3005 12m clin3-cut-5min.mp4\n",
      "3013 12m pt1-cut-5min.mp4\n",
      "3013 12m pt2-cut-5min.mp4\n",
      "3019_12m-cut-5min.mp4\n",
      "3022post-cut.mp4\n",
      "3023 12m pt1-cut-5min.mp4\n",
      "3023 12m pt3-cut-5min.mp4\n",
      "3024 p2post-cut.mp4\n",
      "3032 12m pt2-cut-5min.mp4\n",
      "3034redo1post-cut.mp4\n",
      "3035post-cut.mp4\n",
      "7107_1post-cut.mp4\n",
      "4003 12 mo p 2-cut-5min.mp4\n",
      "4003 12 mo p1-cut-5min.mp4\n",
      "4003 12 mo p3-cut-5min.mp4\n",
      "4003 12 mo p4-cut-5min.mp4\n"
     ]
    }
   ],
   "source": [
    "chr_video_path = '../data/chr'\n",
    "hc_video_path = '../data/hc'\n",
    "video_out_path = '../output/annotated_video'\n",
    "csv_out_path = '../output/gesture'\n",
    "supported_extensions = ['.mp4']\n",
    "\n",
    "# Initialize MediaPipe's Holistic module\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "holistic = mp_holistic.Holistic(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "excluded_files = [\n",
    "    '11002post-cut.mp4',\n",
    "    '11007pt1-cut-5min.mp4',\n",
    "    '11007pt2-cut-5min.mp4',\n",
    "    '11007pt3-cut-5min.mp4',\n",
    "    '11008.1-cut-5min.mp4',\n",
    "    '11008.2-cut-5min.mp4',\n",
    "    '3005 12m clin-cut-5min.mp4',\n",
    "    '3005 12m clin2-cut-5min.mp4',\n",
    "    '3005 12m clin3-cut-5min.mp4',\n",
    "    '3013 12m pt2-cut-5min.mp4',\n",
    "    '3019_12m-cut-5min.mp4',\n",
    "    '3022post-cut.mp4',\n",
    "    '3023 12m pt1-cut-5min.mp4',\n",
    "    '3023 12m pt3-cut-5min.mp4',\n",
    "    '3024 p2post-cut.mp4',\n",
    "    '3032 12m pt2-cut-5min.mp4',\n",
    "    '3034redo1post-cut.mp4',\n",
    "    '3035post-cut.mp4',\n",
    "    '7107_1post-cut.mp4'\n",
    "]\n",
    "\n",
    "for filename in os.listdir(chr_video_path):\n",
    "    if any(filename.endswith(ext) for ext in supported_extensions):\n",
    "        print(filename)\n",
    "        if filename in excluded_files:\n",
    "            continue\n",
    "        video_cut = os.path.join(chr_video_path, filename)\n",
    "        video_out = os.path.join(video_out_path, f'{filename[:-4]}-output.mp4')\n",
    "        output_csv = os.path.join(csv_out_path, f'{filename[:-4]}-gesture.csv')\n",
    "        \n",
    "        process_video(video_cut, video_out, output_csv, mp_drawing, mp_holistic, mp_face_mesh, holistic, face_mesh)\n",
    "\n",
    "\n",
    "for filename in os.listdir(hc_video_path):\n",
    "    if any(filename.endswith(ext) for ext in supported_extensions):\n",
    "        print(filename)\n",
    "        video_cut = os.path.join(hc_video_path, filename)\n",
    "        video_out = os.path.join(video_out_path, f'{filename[:-4]}-output.mp4')\n",
    "        output_csv = os.path.join(csv_out_path, f'{filename[:-4]}-gesture.csv')\n",
    "        process_video(video_cut, video_out, output_csv, mp_drawing, mp_holistic, mp_face_mesh, holistic, face_mesh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
