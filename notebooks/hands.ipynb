{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "grDRXmQavu5Q"
      },
      "source": [
        "### Import dependencies and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPhlat1rv2_G"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import glob\n",
        "from scipy.spatial import ConvexHull\n",
        "import math\n",
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = '../data/CHR/'\n",
        "CHR_videos = ['3022_post.avi', '3035post.avi', '7076 screening.avi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v51XK_MlwTub"
      },
      "outputs": [],
      "source": [
        "video = \"../practicum/3022_cut_5.mp4\"\n",
        "video_cut = \"../practicum/interview_cut_5.mp4\"\n",
        "#video_cut = \"/content/drive/MyDrive/interview-cut.mp4\"\n",
        "hands = \"../practicum/interview-hands.mp4\"\n",
        "hands_csv = \"../practicum/interview.csv\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "soNejGY5wKUm"
      },
      "source": [
        "### Define the pose estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQ65j_OvwD4B"
      },
      "outputs": [],
      "source": [
        "## initialize pose estimator\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_holistic = mp.solutions.holistic\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
        "holistic = mp_holistic.Holistic(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twscgCMLZeUf",
        "outputId": "b5cd94d9-abbe-40b0-8e29-8a27b51566dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "width 1280 height 720 fps 30\n"
          ]
        }
      ],
      "source": [
        "## Load the video\n",
        "cap = cv2.VideoCapture(video)\n",
        "\n",
        "# Get the video dimensions, FPS, and calculate the total number of frames for the first minute\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "print(f\"width {width} height {height} fps {fps}\")\n",
        "\n",
        "frames_to_keep = 60 * fps  # Keep only the first minute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nupkkIMVZw_A"
      },
      "outputs": [],
      "source": [
        "## shortern video to 1 minute and save\n",
        "\n",
        "out = cv2.VideoWriter(video_cut, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "\n",
        "frame_count = 0\n",
        "while cap.isOpened() and frame_count < frames_to_keep:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    # write the frame to the output video\n",
        "    out.write(frame)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUiT-lkOc-tv"
      },
      "outputs": [],
      "source": [
        "## Function definitions\n",
        "\n",
        "\n",
        "\n",
        "# Function to calculate the openness of a pose\n",
        "def pose_openness(holistic_landmarks):\n",
        "    keypoints = [\n",
        "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER],\n",
        "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER],\n",
        "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_HIP],\n",
        "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_HIP],\n",
        "    ]\n",
        "    \n",
        "    coords = np.array([(kp.x, kp.y) for kp in keypoints])\n",
        "    hull = ConvexHull(coords)\n",
        "    \n",
        "    return hull.volume\n",
        "\n",
        "\n",
        "# Function to calculate leaning direction\n",
        "def leaning_direction(holistic_landmarks):\n",
        "    nose = holistic_landmarks.landmark[mp_holistic.PoseLandmark.NOSE]\n",
        "    left_shoulder = holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER]\n",
        "    right_shoulder = holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER]\n",
        "    \n",
        "    avg_shoulder_z = (left_shoulder.z + right_shoulder.z) / 2\n",
        "\n",
        "    if nose.z < avg_shoulder_z:\n",
        "        return \"Forward\"\n",
        "    else:\n",
        "        return \"Backward\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TYIw-lj3ECa"
      },
      "outputs": [],
      "source": [
        "# calculate angle between three landmarks\n",
        "def calculate_angle(l1, l2, l3):\n",
        "\n",
        "    # Calculate the angle between the three points\n",
        "    angle = math.degrees(math.atan2(l3.y - l2.y, l3.x - l2.x) - math.atan2(l1.y - l2.y, l1.x - l2.x))\n",
        "    \n",
        "    # Check if the angle is less than zero.\n",
        "    if angle < 0:\n",
        "        # Add 360 to the found angle.\n",
        "        angle += 360\n",
        "  \n",
        "    return angle\n",
        "\n",
        "\n",
        "def numpy_angle(l1,l2,l3, width, height):\n",
        "  a = np.array([l1.x * width, l1.y * height])\n",
        "  b = np.array([l2.x * width, l2.y * height])\n",
        "  c = np.array([l3.x * width, l3.y * height])\n",
        "\n",
        "  ba = a - b\n",
        "  bc = c - b\n",
        "\n",
        "  cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "  angle = np.arccos(cosine_angle)\n",
        "\n",
        "  return np.degrees(angle)\n",
        "\n",
        "\n",
        "# calculate distance between 2 points\n",
        "def euclidean_distance(p1, p2):\n",
        "    return np.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2)\n",
        "\n",
        "# Hand orientation\n",
        "def orientation(l0, l9): \n",
        "    x0 = l0.x\n",
        "    y0 = l0.y\n",
        "    \n",
        "    x9 = l9.x\n",
        "    y9 = l9.y\n",
        "    \n",
        "    if abs(x9 - x0) < 0.05:      # since tan(0) --> âˆž\n",
        "        m = 1000000000\n",
        "    else:\n",
        "        m = abs((y9 - y0)/(x9 - x0))       \n",
        "        \n",
        "    if m>=0 and m<=1:\n",
        "        if x9 > x0:\n",
        "            return \"Right\"\n",
        "        else:\n",
        "            return \"Left\"\n",
        "    if m>1:\n",
        "        if y9 < y0:       # since, y decreases upwards\n",
        "            return \"Up\"\n",
        "        else:\n",
        "            return \"Down\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfVn8BMEy4tG"
      },
      "outputs": [],
      "source": [
        "# Load the cropped video\n",
        "cap = cv2.VideoCapture(video_cut)\n",
        "\n",
        "# Initialize the VideoWriter\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(hands, fourcc, fps, (width, height))\n",
        "\n",
        "# Initialize variables\n",
        "prev_landmarks = None\n",
        "left_arm_movement = 0\n",
        "right_arm_movement = 0\n",
        "movement_threshold = 0.001  # Adjust the threshold to fine-tune movement detection sensitivity\n",
        "PL = mp_holistic.PoseLandmark\n",
        "HL = mp_holistic.HandLandmark\n",
        "\n",
        "\n",
        "## Arms\n",
        "la_counter = 0 \n",
        "la_vert = None\n",
        "la_leaning = None\n",
        "\n",
        "ra_counter = 0 \n",
        "ra_vert = None\n",
        "ra_leaning = None\n",
        "\n",
        "## Hand\n",
        "lh_stage = None\n",
        "lh_tip_distance = 0\n",
        "lh_orientation = None\n",
        "\n",
        "rh_stage = None\n",
        "rh_tip_distance = 0\n",
        "rh_orientation = None\n",
        "count = 1\n",
        "\n",
        "with open(hands_csv, mode='w', newline='') as csv_file:\n",
        "  writer = csv.writer(csv_file)\n",
        "  writer.writerow(['frame', 'left_arm_angle', 'left_arm_v_movement', 'left_arm_h_movement','right_arm_angle', 'right_arm_v_movement', 'right_arm_h_movement', 'left_hand_orientation', 'right_arm_state', 'right_hand_orientation', 'right_arm_state'])\n",
        "  while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    # Convert the frame to RGB\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process the frame with MediaPipe's Holistic module\n",
        "    results = holistic.process(frame_rgb)\n",
        "\n",
        "    # Draw holistic landmarks on the frame\n",
        "    if results.pose_landmarks:\n",
        "      current = results.pose_landmarks\n",
        "      current_lh = results.left_hand_landmarks\n",
        "      current_rh = results.right_hand_landmarks\n",
        "\n",
        "      mp_drawing.draw_landmarks(frame, current, mp_holistic.POSE_CONNECTIONS)\n",
        "      mp_drawing.draw_landmarks(frame, current_lh, mp_holistic.HAND_CONNECTIONS)\n",
        "      mp_drawing.draw_landmarks(frame, current_rh, mp_holistic.HAND_CONNECTIONS)\n",
        "\n",
        "      ## hand positions\n",
        "      # distance b/w INDEX_FINGER_TIP and THUMB_TIP\n",
        "      if current_lh:\n",
        "        lh_tip_distance = euclidean_distance(current_lh.landmark[HL.INDEX_FINGER_TIP],current_lh.landmark[HL.THUMB_TIP])\n",
        "\n",
        "        if current_lh.landmark[HL.MIDDLE_FINGER_TIP].y < current_lh.landmark[HL.MIDDLE_FINGER_MCP].y and current_lh.landmark[HL.RING_FINGER_TIP].y < current_lh.landmark[HL.RING_FINGER_MCP].y \\\n",
        "          and current_lh.landmark[HL.PINKY_TIP].y < current_lh.landmark[HL.PINKY_TIP].y and lh_tip_distance < 0.015:\n",
        "          lh_stage = 'CLOSED'\n",
        "        else:\n",
        "          lh_stage = 'OPEN'\n",
        "\n",
        "        lh_orientation = orientation(current_lh.landmark[HL.WRIST], current_lh.landmark[HL.MIDDLE_FINGER_MCP])\n",
        "\n",
        "      if current_rh:\n",
        "        rh_tip_distance = euclidean_distance(current_rh.landmark[HL.INDEX_FINGER_TIP],current_rh.landmark[HL.THUMB_TIP])\n",
        "\n",
        "        if current_rh.landmark[HL.MIDDLE_FINGER_TIP].y < current_rh.landmark[HL.MIDDLE_FINGER_MCP].y and current_rh.landmark[HL.RING_FINGER_TIP].y < current_rh.landmark[HL.RING_FINGER_MCP].y \\\n",
        "          and current_rh.landmark[HL.PINKY_TIP].y < current_rh.landmark[HL.PINKY_TIP].y and rh_tip_distance < 0.015:\n",
        "          rh_stage = 'CLOSED'\n",
        "        else:\n",
        "          rh_stage = 'OPEN'\n",
        "\n",
        "        rh_orientation = orientation(current_rh.landmark[HL.WRIST], current_rh.landmark[HL.MIDDLE_FINGER_MCP])\n",
        "\n",
        "      ## Arm positions\n",
        "      # Calculate weather arm is up or down\n",
        "      la_angle = numpy_angle(current.landmark[PL.LEFT_WRIST], current.landmark[PL.LEFT_ELBOW], current.landmark[PL.LEFT_SHOULDER], width, height)\n",
        "      ra_angle = numpy_angle(current.landmark[PL.RIGHT_WRIST], current.landmark[PL.RIGHT_ELBOW], current.landmark[PL.RIGHT_SHOULDER], width, height)\n",
        "\n",
        "      if la_angle > 160:\n",
        "        la_vert = \"DOWN\"\n",
        "      if la_angle < 30 and la_vert =='DOWN':\n",
        "        la_vert=\"UP\"\n",
        "        la_counter +=1\n",
        "\n",
        "      if ra_angle > 160:\n",
        "        ra_vert = \"DOWN\"\n",
        "      if ra_angle < 30 and ra_vert =='DOWN':\n",
        "        ra_vert=\"UP\"\n",
        "        ra_counter +=1\n",
        "      \n",
        "      # Calculate wheather arm is leaning forward\n",
        "      if abs(current.landmark[PL.RIGHT_WRIST].z) > abs(current.landmark[PL.RIGHT_ELBOW].z):\n",
        "        ra_leaning = 'FORWARD'\n",
        "      else:\n",
        "        ra_leaning = 'CALCULATING'\n",
        "\n",
        "      if abs(current.landmark[PL.LEFT_WRIST].z) > abs(current.landmark[PL.LEFT_ELBOW].z) :\n",
        "        la_leaning = 'FORWARD'\n",
        "      else:\n",
        "        la_leaning = 'CALCULATING'\n",
        "\n",
        "      # Detect right arm up/down movement\n",
        "      '''if current.landmark[PL.RIGHT_SHOULDER].y > current.landmark[PL.RIGHT_ELBOW].y and \\\n",
        "          current.landmark[PL.RIGHT_WRIST].y > current.landmark[PL.RIGHT_ELBOW].y :\n",
        "        r_stage = 'UP'\n",
        "    \n",
        "      elif current.landmark[PL.RIGHT_SHOULDER].y > current.landmark[PL.RIGHT_ELBOW].y and \\\n",
        "            current.landmark[PL.RIGHT_ELBOW].y > current.landmark[PL.RIGHT_WRIST].y :\n",
        "        r_stage = 'DOWN'\n",
        "      else:\n",
        "        r_stage = 'CALCULATING'''\n",
        "    \n",
        "      '''if current.landmark[PL.LEFT_SHOULDER].y > current.landmark[PL.LEFT_ELBOW].y and \\\n",
        "          current.landmark[PL.LEFT_WRIST].y > current.landmark[PL.LEFT_ELBOW].y : \n",
        "        l_stage = 'UP'\n",
        "      elif current.landmark[PL.LEFT_SHOULDER].y > current.landmark[PL.LEFT_ELBOW].y and \\\n",
        "            current.landmark[PL.LEFT_ELBOW].y > current.landmark[PL.LEFT_WRIST].y:\n",
        "        l_stage = 'DOWN'\n",
        "      else: \n",
        "        l_stage = 'CALCULATING'''\n",
        "\n",
        "    \n",
        "      l1 = current.landmark[PL.LEFT_SHOULDER]\n",
        "      l2 = current.landmark[PL.LEFT_ELBOW]\n",
        "      l3 = current.landmark[PL.LEFT_WRIST]\n",
        "\n",
        "      r1 = current.landmark[PL.RIGHT_SHOULDER]\n",
        "      r2 = current.landmark[PL.RIGHT_ELBOW]\n",
        "      r3 = current.landmark[PL.RIGHT_WRIST]\n",
        "\n",
        "\n",
        "      cv2.putText(frame, f\"Left shoulder:({round(l1.x,2)}, {round(l1.y,2)}, {round(l1.z,2)}) elbow:({round(l2.x,2)}, {round(l2.y,2)}, {round(l2.z,2)}) wrist: ({round(l3.x,2)}, {round(l3.y,2)}, {round(l3.z,2)})\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "      cv2.putText(frame, f\"Left arm: {la_vert}  {la_leaning}\", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "      cv2.putText(frame, f\"Left arm angle: {la_angle:.2f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "      cv2.putText(frame, f\"Right shoulder:({round(r1.x,2)}, {round(r1.y,2)}, {round(r1.z,2)}) elbow:({round(r2.x,2)}, {round(r2.y,2)}, {round(r2.z,2)}) wrist: ({round(r3.x,2)}, {round(r3.y,2)}, {round(r3.z,2)})\", (10,120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "      cv2.putText(frame, f\"Right arm: {ra_vert}  {ra_leaning}\", (10,150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
        "      cv2.putText(frame, f\"Right arm angle: {ra_angle:.4f}\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
        "\n",
        "      cv2.putText(frame, f\"Left Hand: {lh_tip_distance} {lh_stage} {lh_orientation}\", (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "      cv2.putText(frame, f\"Right Hand: {rh_tip_distance} {rh_stage} {rh_orientation}\", (10, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "\n",
        "      writer.writerow([count, la_angle, la_vert, la_leaning, ra_angle, ra_vert, ra_leaning, lh_orientation, lh_stage, rh_orientation, rh_stage])\n",
        "      # update previous landmarks\n",
        "      prev = current\n",
        "\n",
        "    # Save the frame\n",
        "    out.write(frame)\n",
        "    count = count + 1\n",
        "  \n",
        "  out.release()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "doYUoxTfyuwy"
      },
      "source": [
        "## Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "go1dAnd4yyZ3"
      },
      "outputs": [],
      "source": [
        "# Load the cropped video\n",
        "cap = cv2.VideoCapture(video_cut)\n",
        "\n",
        "# Initialize the VideoWriter\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(hands, fourcc, fps, (width, height))\n",
        "\n",
        "# Initialize variables\n",
        "prev_landmarks = None\n",
        "left_arm_movement = 0\n",
        "right_arm_movement = 0\n",
        "movement_threshold = 0.001  # Adjust the threshold to fine-tune movement detection sensitivity\n",
        "PL = mp_holistic.PoseLandmark\n",
        "HL = mp_holistic.HandLandmark\n",
        "\n",
        "\n",
        "## Arms\n",
        "la_counter = 0 \n",
        "la_vert = None\n",
        "la_leaning = None\n",
        "\n",
        "ra_counter = 0 \n",
        "ra_vert = None\n",
        "ra_leaning = None\n",
        "\n",
        "## Hand\n",
        "lh_stage = None\n",
        "lh_tip_distance = 0\n",
        "\n",
        "rh_stage = None\n",
        "rh_tip_distance = 0\n",
        "count = 1\n",
        "\n",
        "with open(hands_csv, mode='w', newline='') as csv_file:\n",
        "  writer = csv.writer(csv_file)\n",
        "  writer.writerow(['frame', 'left_arm_angle', 'left_arm_v_movement', 'left_arm_h_movement','right_arm_angle', 'right_arm_v_movement', 'right_arm_h_movement'])\n",
        "  while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "\n",
        "    # Convert the frame to RGB\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process the frame with MediaPipe's Holistic module\n",
        "    results = holistic.process(frame_rgb)\n",
        "\n",
        "    # Draw holistic landmarks on the frame\n",
        "    if results.pose_landmarks:\n",
        "      current = results.pose_landmarks\n",
        "      current_lh = results.left_hand_landmarks\n",
        "      current_rh = results.right_hand_landmarks\n",
        "\n",
        "      mp_drawing.draw_landmarks(frame, current, mp_holistic.POSE_CONNECTIONS)\n",
        "      mp_drawing.draw_landmarks(frame, current_lh, mp_holistic.HAND_CONNECTIONS)\n",
        "      mp_drawing.draw_landmarks(frame, current_rh, mp_holistic.HAND_CONNECTIONS)\n",
        "\n",
        "      ## hand positions\n",
        "      # distance b/w INDEX_FINGER_TIP and THUMB_TIP\n",
        "      if current_lh:\n",
        "        lh_tip_distance = euclidean_distance(current_lh.landmark[HL.INDEX_FINGER_TIP],current_lh.landmark[HL.THUMB_TIP])\n",
        "\n",
        "        if current_lh.landmark[HL.MIDDLE_FINGER_TIP].y < current_lh.landmark[HL.MIDDLE_FINGER_MCP].y and current_lh.landmark[HL.RING_FINGER_TIP].y < current_lh.landmark[HL.RING_FINGER_MCP].y \\\n",
        "          and current_lh.landmark[HL.PINKY_TIP].y < current_lh.landmark[HL.PINKY_TIP].y and lh_tip_distance < 0.015:\n",
        "          lh_stage = 'CLOSED'\n",
        "        else:\n",
        "          lh_stage = 'OPEN'\n",
        "\n",
        "      if current_rh:\n",
        "        rh_tip_distance = euclidean_distance(current_rh.landmark[HL.INDEX_FINGER_TIP],current_rh.landmark[HL.THUMB_TIP])\n",
        "        \n",
        "        if current_rh.landmark[HL.MIDDLE_FINGER_TIP].y < current_rh.landmark[HL.MIDDLE_FINGER_MCP].y and current_rh.landmark[HL.RING_FINGER_TIP].y < current_rh.landmark[HL.RING_FINGER_MCP].y \\\n",
        "          and current_rh.landmark[HL.PINKY_TIP].y < current_rh.landmark[HL.PINKY_TIP].y and rh_tip_distance < 0.015:\n",
        "          rh_stage = 'CLOSED'\n",
        "        else:\n",
        "          rh_stage = 'OPEN'\n",
        "\n",
        "      ## Arm positions\n",
        "      # Calculate weather arm is up or down\n",
        "      la_angle = numpy_angle(current.landmark[PL.LEFT_WRIST], current.landmark[PL.LEFT_ELBOW], current.landmark[PL.LEFT_SHOULDER], width, height)\n",
        "      ra_angle = numpy_angle(current.landmark[PL.RIGHT_WRIST], current.landmark[PL.RIGHT_ELBOW], current.landmark[PL.RIGHT_SHOULDER], width, height)\n",
        "\n",
        "      if la_angle > 160:\n",
        "        la_vert = \"DOWN\"\n",
        "      if la_angle < 30 and la_vert =='DOWN':\n",
        "        la_vert=\"UP\"\n",
        "        la_counter +=1\n",
        "\n",
        "      if ra_angle > 160:\n",
        "        ra_vert = \"DOWN\"\n",
        "      if ra_angle < 30 and ra_vert =='DOWN':\n",
        "        ra_vert=\"UP\"\n",
        "        ra_counter +=1\n",
        "      \n",
        "      # Calculate wheather arm is leaning forward\n",
        "      if abs(current.landmark[PL.RIGHT_WRIST].z) > abs(current.landmark[PL.RIGHT_ELBOW].z):\n",
        "        ra_leaning = 'FORWARD'\n",
        "      else:\n",
        "        ra_leaning = 'CALCULATING'\n",
        "\n",
        "      if abs(current.landmark[PL.LEFT_WRIST].z) > abs(current.landmark[PL.LEFT_ELBOW].z) :\n",
        "        la_leaning = 'FORWARD'\n",
        "      else:\n",
        "        la_leaning = 'CALCULATING'\n",
        "\n",
        "      # Detect right arm up/down movement\n",
        "      '''if current.landmark[PL.RIGHT_SHOULDER].y > current.landmark[PL.RIGHT_ELBOW].y and \\\n",
        "          current.landmark[PL.RIGHT_WRIST].y > current.landmark[PL.RIGHT_ELBOW].y :\n",
        "        r_stage = 'UP'\n",
        "    \n",
        "      elif current.landmark[PL.RIGHT_SHOULDER].y > current.landmark[PL.RIGHT_ELBOW].y and \\\n",
        "            current.landmark[PL.RIGHT_ELBOW].y > current.landmark[PL.RIGHT_WRIST].y :\n",
        "        r_stage = 'DOWN'\n",
        "      else:\n",
        "        r_stage = 'CALCULATING'''\n",
        "    \n",
        "      '''if current.landmark[PL.LEFT_SHOULDER].y > current.landmark[PL.LEFT_ELBOW].y and \\\n",
        "          current.landmark[PL.LEFT_WRIST].y > current.landmark[PL.LEFT_ELBOW].y : \n",
        "        l_stage = 'UP'\n",
        "      elif current.landmark[PL.LEFT_SHOULDER].y > current.landmark[PL.LEFT_ELBOW].y and \\\n",
        "            current.landmark[PL.LEFT_ELBOW].y > current.landmark[PL.LEFT_WRIST].y:\n",
        "        l_stage = 'DOWN'\n",
        "      else: \n",
        "        l_stage = 'CALCULATING'''\n",
        "\n",
        "    \n",
        "      l1 = current.landmark[PL.LEFT_SHOULDER]\n",
        "      l2 = current.landmark[PL.LEFT_ELBOW]\n",
        "      l3 = current.landmark[PL.LEFT_WRIST]\n",
        "\n",
        "      r1 = current.landmark[PL.RIGHT_SHOULDER]\n",
        "      r2 = current.landmark[PL.RIGHT_ELBOW]\n",
        "      r3 = current.landmark[PL.RIGHT_WRIST]\n",
        "\n",
        "\n",
        "      cv2.putText(frame, f\"Left shoulder:({round(l1.x,2)}, {round(l1.y,2)}, {round(l1.z,2)}) elbow:({round(l2.x,2)}, {round(l2.y,2)}, {round(l2.z,2)}) wrist: ({round(l3.x,2)}, {round(l3.y,2)}, {round(l3.z,2)})\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "      cv2.putText(frame, f\"Left arm: {la_vert}  {la_leaning}\", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "      cv2.putText(frame, f\"Left arm angle: {la_angle:.2f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "      cv2.putText(frame, f\"Right shoulder:({round(r1.x,2)}, {round(r1.y,2)}, {round(r1.z,2)}) elbow:({round(r2.x,2)}, {round(r2.y,2)}, {round(r2.z,2)}) wrist: ({round(r3.x,2)}, {round(r3.y,2)}, {round(r3.z,2)})\", (10,120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "      cv2.putText(frame, f\"Right arm: {ra_vert}  {ra_leaning}\", (10,150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
        "      cv2.putText(frame, f\"Right arm angle: {ra_angle:.4f}\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
        "\n",
        "      cv2.putText(frame, f\"Left Hand: {lh_tip_distance} {lh_stage}\", (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "      cv2.putText(frame, f\"Right Hand: {rh_tip_distance} {rh_stage}\", (10, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "\n",
        "      writer.writerow([count, la_angle, la_vert, la_leaning, ra_angle, ra_vert, ra_leaning])\n",
        "      # update previous landmarks\n",
        "      prev = current\n",
        "\n",
        "    # Save the frame\n",
        "    out.write(frame)\n",
        "    count = count + 1\n",
        "  \n",
        "  out.release()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
