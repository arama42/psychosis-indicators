{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (0.9.3.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from mediapipe) (23.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from mediapipe) (3.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from mediapipe) (1.23.5)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from mediapipe) (4.7.0.72)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\rcz8260\\appdata\\local\\miniconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Head pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import cv2\\nimport mediapipe as mp\\nimport numpy as np\\nimport time\\nimport csv\\nimport os\\n\\nmp_face_mesh = mp.solutions.face_mesh\\nface_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\\n\\nmp_drawing = mp.solutions.drawing_utils\\n\\ndrawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\\n\\n# Define the input video and output video paths\\ninput_video_path = r\\'/Users/aanchalsahu/Downloads/Test.mp4\\'\\n#output_video_path = \\'/Users/aanchalsahu/Downloads/TestOutput.mp4\\'\\n\\n# Define the CSV file path\\ncsv_file_path = r\\'/Users/aanchalsahu/Downloads/TestOutput.csv\\'\\ncap = cv2.VideoCapture(input_video_path)\\n# Initialize a frame counter\\n\\n# Initialize the CSV file and write the header if the file doesn\\'t exist\\ncsv_header = [\\'Frame\\', \\'Landmarks\\', \\'Head Pose X\\', \\'Head Pose Y\\', \\'Head Pose Z\\', \\'Direction\\', \\'FPS\\']\\nwrite_header = not os.path.isfile(csv_file_path)\\n\\n# Initialize the CSV file path and header\\ncsv_file_path = \\'features.csv\\'\\ncsv_header = [\\'Frame\\', \\'Landmarks\\', \\'X\\', \\'Y\\', \\'Z\\', \\'Direction\\', \\'FPS\\']\\n\\n# Open the CSV file in append mode\\nwith open(csv_file_path, \\'a\\', newline=\\'\\') as csvfile:\\n    writer = csv.writer(csvfile)\\n\\n    # Write the header row if it\\'s the first write\\n    write_header = csvfile.tell() == 0\\n    if write_header:\\n        writer.writerow(csv_header)\\n\\n    # Process each frame in the video\\n    frame_count = 0\\n    while cap.isOpened():\\n        success, image = cap.read()\\n        if not success:\\n            break\\n\\n        start = time.time()\\n\\n        # Flip the image horizontally for a later selfie-view display\\n        # Also convert the color space from BGR to RGB\\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\n\\n        # To improve performance\\n        image.flags.writeable = False\\n        \\n        # Get the result\\n        results = face_mesh.process(image)\\n        \\n        # To improve performance\\n        image.flags.writeable = True\\n        \\n        # Convert the color space from RGB to BGR\\n        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\\n\\n        img_h, img_w, img_c = image.shape\\n        face_3d = []\\n        face_2d = []\\n\\n        if results.multi_face_landmarks:\\n            for face_landmarks in results.multi_face_landmarks:\\n                face_2d = []\\n                face_3d = []\\n                for idx, lm in enumerate(face_landmarks.landmark):\\n                    if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\\n                        if idx == 1:\\n                            nose_2d = (lm.x * img_w, lm.y * img_h)\\n                            nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\\n\\n                        x, y = int(lm.x * img_w), int(lm.y * img_h)\\n\\n                        # Get the 2D Coordinates\\n                        face_2d.append([x, y])\\n\\n                        # Get the 3D Coordinates\\n                        face_3d.append([x, y, lm.z])       \\n\\n                # Convert it to the NumPy array\\n                face_2d = np.array(face_2d, dtype=np.float64)\\n\\n                # Convert it to the NumPy array\\n                face_3d = np.array(face_3d, dtype=np.float64)\\n\\n                # The camera matrix\\n                focal_length = 1 * img_w\\n\\n                cam_matrix = np.array([[focal_length, 0, img_h / 2],\\n                                       [0, focal_length, img_w / 2],\\n                                       [0, 0, 1]])\\n\\n                # The distortion parameters\\n                dist_matrix = np.zeros((4, 1), dtype=np.float64)\\n\\n                # Solve PnP\\n                success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\\n\\n                # Get rotational matrix\\n                rmat, jac = cv2.Rodrigues(rot_vec)\\n\\n                # Get angles\\n                angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\\n\\n                # Get the y rotation degree\\n                x = angles[0] * 360\\n                y = angles[1] * 360\\n                z = angles[2] * 360\\n\\n                # See where the user\\'s head tilting\\n                if y < -1.25:\\n                    text = \"Left tilt\"\\n                    if x < -1.2:\\n                        text = \"Looking Down and left\"\\n                    if x > 6.0:\\n                        text = \"Looking Up and left\"\\n                elif y > 2.21:\\n                    text = \"Right tilt\"\\n                    if x < -1.2:\\n                        text = \"Looking Down and right\"\\n                    if x > 6.0:\\n                        text = \"Looking Up and right\"\\n                else:\\n                    text = \"Forward\"\\n\\n                # Display the nose direction\\n                nose_3d_projection, jacobian = cv2.projectPoints(nose_3d, rot_vec, trans_vec, cam_matrix, dist_matrix)\\n\\n                p1 = (int(nose_2d[0]), int(nose_2d[1]))\\n                p2 = (int(nose_2d[0] + y * 10), int(nose_2d[1] - x * 10))\\n\\n                # Increase line length by multiplying x and y values with a scaling factor\\n                line_length_scale = 30\\n                p2 = (int(nose_2d[0] + y * line_length_scale), int(nose_2d[1] - x * line_length_scale))\\n\\n                cv2.line(image, p1, p2, (255, 0, 0), 3)\\n\\n                # Add the text on the image\\n                cv2.putText(image, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 2)\\n                cv2.putText(image, \"x: \" + str(np.round(x,2)), (600, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\\n                cv2.putText(image, \"y: \" + str(np.round(y,2)), (600, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\\n                cv2.putText(image, \"z: \" + str(np.round(z,2)), (600, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\\n\\n                end = time.time()\\n                totalTime = end - start\\n\\n                fps = 1 / totalTime\\n\\n                # Write the features to the CSV file\\n                csv_row = [frame_count, landmarks, x, y, z, text, fps]\\n                writer.writerow(csv_row)\\n\\n        cv2.imshow(\\'Head Pose Estimation\\', image)\\n        frame_count += 1\\n\\n        if cv2.waitKey(1) & 0xFF == ord(\\'q\\'):\\n            break\\n\\ncap.release()\\ncv2.destroyAllWindows()'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# Define the input video and output video paths\n",
    "input_video_path = r'/Users/aanchalsahu/Downloads/Test.mp4'\n",
    "#output_video_path = '/Users/aanchalsahu/Downloads/TestOutput.mp4'\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = r'/Users/aanchalsahu/Downloads/TestOutput.csv'\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "# Initialize a frame counter\n",
    "\n",
    "# Initialize the CSV file and write the header if the file doesn't exist\n",
    "csv_header = ['Frame', 'Landmarks', 'Head Pose X', 'Head Pose Y', 'Head Pose Z', 'Direction', 'FPS']\n",
    "write_header = not os.path.isfile(csv_file_path)\n",
    "\n",
    "# Initialize the CSV file path and header\n",
    "csv_file_path = 'features.csv'\n",
    "csv_header = ['Frame', 'Landmarks', 'X', 'Y', 'Z', 'Direction', 'FPS']\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header row if it's the first write\n",
    "    write_header = csvfile.tell() == 0\n",
    "    if write_header:\n",
    "        writer.writerow(csv_header)\n",
    "\n",
    "    # Process each frame in the video\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        # Also convert the color space from BGR to RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # To improve performance\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Get the result\n",
    "        results = face_mesh.process(image)\n",
    "        \n",
    "        # To improve performance\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # Convert the color space from RGB to BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        img_h, img_w, img_c = image.shape\n",
    "        face_3d = []\n",
    "        face_2d = []\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                face_2d = []\n",
    "                face_3d = []\n",
    "                for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                    if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                        if idx == 1:\n",
    "                            nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                            nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
    "\n",
    "                        x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "                        # Get the 2D Coordinates\n",
    "                        face_2d.append([x, y])\n",
    "\n",
    "                        # Get the 3D Coordinates\n",
    "                        face_3d.append([x, y, lm.z])       \n",
    "\n",
    "                # Convert it to the NumPy array\n",
    "                face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "                # Convert it to the NumPy array\n",
    "                face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "                # The camera matrix\n",
    "                focal_length = 1 * img_w\n",
    "\n",
    "                cam_matrix = np.array([[focal_length, 0, img_h / 2],\n",
    "                                       [0, focal_length, img_w / 2],\n",
    "                                       [0, 0, 1]])\n",
    "\n",
    "                # The distortion parameters\n",
    "                dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "                # Solve PnP\n",
    "                success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "                # Get rotational matrix\n",
    "                rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "                # Get angles\n",
    "                angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "                # Get the y rotation degree\n",
    "                x = angles[0] * 360\n",
    "                y = angles[1] * 360\n",
    "                z = angles[2] * 360\n",
    "\n",
    "                # See where the user's head tilting\n",
    "                if y < -1.25:\n",
    "                    text = \"Left tilt\"\n",
    "                    if x < -1.2:\n",
    "                        text = \"Looking Down and left\"\n",
    "                    if x > 6.0:\n",
    "                        text = \"Looking Up and left\"\n",
    "                elif y > 2.21:\n",
    "                    text = \"Right tilt\"\n",
    "                    if x < -1.2:\n",
    "                        text = \"Looking Down and right\"\n",
    "                    if x > 6.0:\n",
    "                        text = \"Looking Up and right\"\n",
    "                else:\n",
    "                    text = \"Forward\"\n",
    "\n",
    "                # Display the nose direction\n",
    "                nose_3d_projection, jacobian = cv2.projectPoints(nose_3d, rot_vec, trans_vec, cam_matrix, dist_matrix)\n",
    "\n",
    "                p1 = (int(nose_2d[0]), int(nose_2d[1]))\n",
    "                p2 = (int(nose_2d[0] + y * 10), int(nose_2d[1] - x * 10))\n",
    "\n",
    "                # Increase line length by multiplying x and y values with a scaling factor\n",
    "                line_length_scale = 30\n",
    "                p2 = (int(nose_2d[0] + y * line_length_scale), int(nose_2d[1] - x * line_length_scale))\n",
    "\n",
    "                cv2.line(image, p1, p2, (255, 0, 0), 3)\n",
    "\n",
    "                # Add the text on the image\n",
    "                cv2.putText(image, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 2)\n",
    "                cv2.putText(image, \"x: \" + str(np.round(x,2)), (600, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.putText(image, \"y: \" + str(np.round(y,2)), (600, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.putText(image, \"z: \" + str(np.round(z,2)), (600, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "                end = time.time()\n",
    "                totalTime = end - start\n",
    "\n",
    "                fps = 1 / totalTime\n",
    "\n",
    "                # Write the features to the CSV file\n",
    "                csv_row = [frame_count, landmarks, x, y, z, text, fps]\n",
    "                writer.writerow(csv_row)\n",
    "\n",
    "        cv2.imshow('Head Pose Estimation', image)\n",
    "        frame_count += 1\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/Users/aanchalsahu/Downloads/OutputFolder/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m out \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoWriter(video_output, fourcc, fps, (frame_width, frame_height))\n\u001b[0;32m     19\u001b[0m \u001b[39m# Get a sorted list of image file names in the source folder\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m images \u001b[39m=\u001b[39m [img \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(source_folder) \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39mendswith((\u001b[39m\"\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.jpeg\u001b[39m\u001b[39m\"\u001b[39m))]\n\u001b[0;32m     21\u001b[0m images\u001b[39m.\u001b[39msort()\n\u001b[0;32m     23\u001b[0m \u001b[39m# Iterate through the images and add them to the video\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/Users/aanchalsahu/Downloads/OutputFolder/'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Define the source folder containing the images\n",
    "source_folder = '/Users/aanchalsahu/Downloads/OutputFolder/'\n",
    "\n",
    "# Define the output video file\n",
    "video_output = '/Users/aanchalsahu/Downloads/TestOutput.mp4'\n",
    "\n",
    "# Video settings\n",
    "fps = 30  # Frame rate (frames per second)\n",
    "frame_width = 1920\n",
    "frame_height = 1080\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Video codec\n",
    "\n",
    "# Initialize the VideoWriter\n",
    "out = cv2.VideoWriter(video_output, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Get a sorted list of image file names in the source folder\n",
    "images = [img for img in os.listdir(source_folder) if img.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "images.sort()\n",
    "\n",
    "# Iterate through the images and add them to the video\n",
    "for image_file in images:\n",
    "    image_path = os.path.join(source_folder, image_file)\n",
    "    frame = cv2.imread(image_path)\n",
    "\n",
    "    # Resize the frame if necessary\n",
    "    if frame.shape[:2] != (frame_height, frame_width):\n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "\n",
    "    # Write the frame to the video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the VideoWriter and close all windows\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Video created successfully.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# Define the input video and output video paths\n",
    "# input_video_path = r'/Users/aanchalsahu/Downloads/Test.mp4'\n",
    "input_video_path = r'C:\\Users\\rcz8260\\Desktop\\practicum\\3035_cut_5.mp4'\n",
    "# Define the CSV file path\n",
    "csv_file_path = r'head_output.csv'\n",
    "#output_video_path = '/Users/aanchalsahu/Downloads/TestOutput.mp4'\n",
    "\n",
    "'''# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))\n",
    "'''\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "output_video = cv2.VideoWriter('head_output.mp4', fourcc, fps, (128,128))\n",
    "# Initialize the CSV file and write the header\n",
    "csv_header = ['Frame', 'Landmarks', 'Head Pose X', 'Head Pose Y', 'Head Pose Z', 'Direction', 'FPS']\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(csv_header)\n",
    "        \n",
    "    # Initialize a frame counter\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display\n",
    "        # Also convert the color space from BGR to RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # To improve performance\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # To improve performance\n",
    "        image.flags.writeable = True\n",
    "        # Get the result\n",
    "        results = face_mesh.process(image)\n",
    "        # Convert the color space from RGB to BGR\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        img_h, img_w, img_c = image.shape\n",
    "        face_3d = []\n",
    "        face_2d = []\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # Extract face landmarks\n",
    "                landmarks = []\n",
    "                for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                    landmarks.append((lm.x, lm.y, lm.z))\n",
    "                    if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                        if idx == 1:\n",
    "                            nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                            nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
    "\n",
    "                        x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "                        # Get the 2D Coordinates\n",
    "                        face_2d.append([x, y])\n",
    "\n",
    "                        # Get the 3D Coordinates\n",
    "                        face_3d.append([x, y, lm.z])       \n",
    "                \n",
    "                # Convert it to the NumPy array\n",
    "                face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "                # Convert it to the NumPy array\n",
    "                face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "                # The camera matrix\n",
    "                focal_length = 1 * img_w\n",
    "\n",
    "                cam_matrix = np.array([ [focal_length, 0, img_h / 2],\n",
    "                                        [0, focal_length, img_w / 2],\n",
    "                                        [0, 0, 1]])\n",
    "\n",
    "                # The distortion parameters\n",
    "                dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "                # Solve PnP\n",
    "                success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "                # Get rotational matrix\n",
    "                rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "                # Get angles\n",
    "                angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "                # Get the y rotation degree\n",
    "                x = angles[0] * 360\n",
    "                y = angles[1] * 360\n",
    "                z = angles[2] * 360\n",
    "\n",
    "                # See where the user's head tilting\n",
    "                if y < -1.25:\n",
    "                    text = \"Left tilt\"\n",
    "                    if x < -1.2:\n",
    "                        text = \"Looking Down and left\"\n",
    "                    if x > 6.0:\n",
    "                        text = \"Looking Up and left\"\n",
    "                \n",
    "                elif y > 2.21:\n",
    "                    text = \"Right tilt\"\n",
    "                    if x < -1.2:\n",
    "                        text = \"Looking Down and right\"\n",
    "                    if x > 6.0:\n",
    "                        text = \"Looking Up and right\"\n",
    "                else:\n",
    "                    text = \"Forward\"\n",
    "\n",
    "                # Display the nose direction\n",
    "                nose_3d_projection, jacobian = cv2.projectPoints(nose_3d, rot_vec, trans_vec, cam_matrix, dist_matrix)\n",
    "\n",
    "                p1 = (int(nose_2d[0]), int(nose_2d[1]))\n",
    "                p2 = (int(nose_2d[0] + y * 10), int(nose_2d[1] - x * 10))\n",
    "\n",
    "                # Increase line length by multiplying x and y values with a scaling factor\n",
    "                line_length_scale = 30\n",
    "                p2 = (int(nose_2d[0] + y * line_length_scale), int(nose_2d[1] - x * line_length_scale))\n",
    "\n",
    "                cv2.line(image, p1, p2, (255, 0, 0), 3)\n",
    "\n",
    "                # Add the text on the image\n",
    "                cv2.putText(image, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 0, 0), 2)\n",
    "                cv2.putText(image, \"x: \" + str(np.round(x,2)), (600, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.putText(image, \"y: \" + str(np.round(y,2)), (600, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                cv2.putText(image, \"z: \" + str(np.round(z,2)), (600, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                \n",
    "\n",
    "            end = time.time()\n",
    "            totalTime = end - start    \n",
    "            fps = 1 / totalTime\n",
    "            #print(\"FPS: \", fps)\n",
    "            cv2.putText(image, f'FPS: {int(fps)}', (20,650), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "            csv_row = [frame_count, landmarks, x, y, z, text, fps]\n",
    "            writer.writerow(csv_row)\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "                        image=image,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        \n",
    "                        landmark_drawing_spec=drawing_spec,\n",
    "                        connection_drawing_spec=drawing_spec)\n",
    "                \n",
    "        cv2.imshow('Head Pose Estimation',image)\n",
    "        # Save the frame as an image\n",
    "        #cv2.imwrite(output_video_path + f'frame_{frame_count:05d}.jpg', image)\n",
    "\n",
    "        frame_count += 1\n",
    "        # cv2.imwrite('frame' + str(count) + '.jpg', frame)\n",
    "        output_video.write(image)\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #             break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "            # Release resources\n",
    "    cap.release()\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yaw, pitch, roll without thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "# Function to calculate head pose angles\n",
    "def calculate_head_pose(left_eye, right_eye, nose_tip):\n",
    "    # Calculate the vector between the eyes\n",
    "    eye_vector = (right_eye[0] - left_eye[0], right_eye[1] - left_eye[1], right_eye[2] - left_eye[2])\n",
    "    \n",
    "    # Calculate the yaw angle\n",
    "    yaw = math.degrees(math.atan2(eye_vector[2], eye_vector[0])) - 90.0\n",
    "    \n",
    "    # Calculate the pitch angle\n",
    "    pitch = math.degrees(math.atan2(eye_vector[1], eye_vector[0]))\n",
    "    \n",
    "    # Calculate the roll angle\n",
    "    roll = math.degrees(math.atan2(nose_tip[1] - (left_eye[1] + right_eye[1]) / 2, nose_tip[2] - (left_eye[2] + right_eye[2]) / 2))\n",
    "    \n",
    "    return yaw, pitch, roll\n",
    "\n",
    "# Initialize Mediapipe Face Mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Initialize VideoCapture\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\rcz8260\\Desktop\\practicum\\interview_cut_5.mp4')\n",
    "\n",
    "# Create a Mediapipe Face Mesh object\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, min_detection_confidence=0.5)\n",
    "\n",
    "# Process each frame in the video\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    # Convert the image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image with Mediapipe Face Mesh\n",
    "    results = face_mesh.process(image_rgb)\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Extract the relevant landmarks for head pose estimation\n",
    "            left_eye = (face_landmarks.landmark[33].x, face_landmarks.landmark[33].y, face_landmarks.landmark[33].z)\n",
    "            right_eye = (face_landmarks.landmark[263].x, face_landmarks.landmark[263].y, face_landmarks.landmark[263].z)\n",
    "            nose_tip = (face_landmarks.landmark[1].x, face_landmarks.landmark[1].y, face_landmarks.landmark[1].z)\n",
    "            \n",
    "            # Calculate the head pose angles\n",
    "            yaw, pitch, roll = calculate_head_pose(left_eye, right_eye, nose_tip)\n",
    "            \n",
    "            # Display the head pose angles\n",
    "            cv2.putText(image, f\"Yaw: {yaw:.2f}\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(image, f\"Pitch: {pitch:.2f}\", (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(image, f\"Roll: {roll:.2f}\", (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow('Head Pose Estimation', image)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
