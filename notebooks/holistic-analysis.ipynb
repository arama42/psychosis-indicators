{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install mediapipe","metadata":{"execution":{"iopub.status.busy":"2023-05-06T04:13:23.027016Z","iopub.execute_input":"2023-05-06T04:13:23.027423Z","iopub.status.idle":"2023-05-06T04:13:37.639155Z","shell.execute_reply.started":"2023-05-06T04:13:23.027390Z","shell.execute_reply":"2023-05-06T04:13:37.637734Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting mediapipe\n  Downloading mediapipe-0.9.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.9/33.9 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mediapipe) (3.6.3)\nRequirement already satisfied: protobuf<4,>=3.11 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (3.20.3)\nRequirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (22.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from mediapipe) (1.23.5)\nRequirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.10/site-packages (from mediapipe) (4.5.4.60)\nCollecting sounddevice>=0.4.4\n  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from mediapipe) (1.4.0)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe) (23.3.3)\nRequirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (21.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (2.8.2)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.0.9)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (9.5.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.0.7)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.39.3)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\nInstalling collected packages: sounddevice, mediapipe\nSuccessfully installed mediapipe-0.9.3.0 sounddevice-0.4.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"Shorten the video into 1 minute","metadata":{}},{"cell_type":"code","source":"# Load the video\ninput_video_path = \"/kaggle/input/gesturevideo/video_original.mp4\"\ncap = cv2.VideoCapture(input_video_path)\n\n# Get the video dimensions, FPS, and calculate the total number of frames for the first minute\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nframes_to_keep = 60 * fps  # Keep only the first minute\n\n# Initialize the VideoWriter\noutput_video_path = \"video_cut.mp4\"\nfourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\nout = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n\nframe_count = 0\nwhile cap.isOpened() and frame_count < frames_to_keep:\n    ret, frame = cap.read()\n\n    if not ret:\n        break\n\n    # Write the frame to the output video\n    out.write(frame)\n\n    frame_count += 1\n\n# Release resources\ncap.release()\nout.release()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T04:42:35.456262Z","iopub.execute_input":"2023-05-06T04:42:35.456666Z","iopub.status.idle":"2023-05-06T04:42:37.048242Z","shell.execute_reply.started":"2023-05-06T04:42:35.456632Z","shell.execute_reply":"2023-05-06T04:42:37.047312Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Process video to get openness, total movement, and leaning direction","metadata":{}},{"cell_type":"code","source":"import cv2\nimport mediapipe as mp\nimport numpy as np\nfrom scipy.spatial import ConvexHull\n\n# Initialize MediaPipe's Holistic module\nmp_drawing = mp.solutions.drawing_utils\nmp_holistic = mp.solutions.holistic\n\n# Function to calculate the Euclidean distance between two points\ndef euclidean_distance(p1, p2):\n    return np.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2)\n\n# Function to calculate the openness of a pose\ndef pose_openness(holistic_landmarks):\n    keypoints = [\n        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER],\n        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER],\n        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_HIP],\n        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_HIP],\n    ]\n    \n    coords = np.array([(kp.x, kp.y) for kp in keypoints])\n    hull = ConvexHull(coords)\n    \n    return hull.volume\n\n# Function to calculate leaning direction\ndef leaning_direction(holistic_landmarks):\n    nose = holistic_landmarks.landmark[mp_holistic.PoseLandmark.NOSE]\n    left_shoulder = holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER]\n    right_shoulder = holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER]\n    \n    avg_shoulder_z = (left_shoulder.z + right_shoulder.z) / 2\n\n    if nose.z < avg_shoulder_z:\n        return \"Forward\"\n    else:\n        return \"Backward\"\n    \n# Load the video\nvideo_path = \"/kaggle/working/video_cut.mp4\"\ncap = cv2.VideoCapture(video_path)\n\n# Get the video dimensions and FPS\nwidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nheight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = int(cap.get(cv2.CAP_PROP_FPS))\n\n# Initialize the VideoWriter\noutput_filename = \"output_video.mp4\"\nfourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # You can also use \"XVID\" or \"MJPG\" for AVI files\nout = cv2.VideoWriter(output_filename, fourcc, fps, (width, height))\n\n# Initialize variables\nprev_landmarks = None\ntotal_movement = 0\nmovement_threshold = 0.001  # Adjust the threshold to fine-tune movement detection sensitivity\nkeypoints_to_track = [\n    mp_holistic.PoseLandmark.LEFT_WRIST,\n    mp_holistic.PoseLandmark.RIGHT_WRIST,\n    mp_holistic.PoseLandmark.LEFT_ANKLE,\n    mp_holistic.PoseLandmark.RIGHT_ANKLE,\n]\n\n# Process the video frames\ncount = 0 \nwith mp_holistic.Holistic(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n    while cap.isOpened():\n        ret, frame = cap.read()\n\n        if not ret:\n            break\n\n        # Convert the frame to RGB\n        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n\n        # Process the frame with MediaPipe's Holistic module\n        results = holistic.process(frame_rgb)\n\n        # Draw holistic landmarks on the frame\n        if results.pose_landmarks:\n            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n\n            # Calculate the total movement\n            if prev_landmarks:\n                frame_movement = 0\n                for kp in keypoints_to_track:\n                    distance = euclidean_distance(results.pose_landmarks.landmark[kp], prev_landmarks.landmark[kp])\n                    frame_movement += distance\n\n                if frame_movement > movement_threshold:\n                    total_movement += frame_movement\n\n            prev_landmarks = results.pose_landmarks\n            # Calculate and display the total movement and pose openness on the frame\n            openness_value = pose_openness(results.pose_landmarks)\n            cv2.putText(frame, f\"Total Movement: {total_movement:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n            cv2.putText(frame, f\"Pose Openness: {openness_value:.4f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n            # Calculate and display the leaning direction\n            leaning_dir = leaning_direction(results.pose_landmarks)\n            cv2.putText(frame, f\"Leaning: {leaning_dir}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n\n        # Save the frame\n        cv2.imwrite('frame' + str(count) + '.jpg', frame)\n        out.write(frame)\n    out.release()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-06T05:34:43.074821Z","iopub.execute_input":"2023-05-06T05:34:43.075305Z","iopub.status.idle":"2023-05-06T05:37:02.793170Z","shell.execute_reply.started":"2023-05-06T05:34:43.075270Z","shell.execute_reply":"2023-05-06T05:37:02.791784Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}