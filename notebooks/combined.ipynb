{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Import dependencies and load data"
      ],
      "metadata": {
        "id": "YGLuYN-29bGm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyKyMKwN9Zb3",
        "outputId": "77254d31-6b1f-425c-a877-dd98fe6953cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.27.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.25.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install mediapipe\n",
        "!pip install moviepy\n",
        "!pip install SpeechRecognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import glob\n",
        "from scipy.spatial import ConvexHull\n",
        "import math\n",
        "import csv\n",
        "\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "import librosa\n",
        "from moviepy.editor import VideoFileClip\n",
        "import speech_recognition as sr"
      ],
      "metadata": {
        "id": "TCXF8tkl9g0j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5hTw3L3_BiP",
        "outputId": "1bbaa07c-e6bc-48c4-8d37-7e3b89897878"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video = \"/content/drive/MyDrive/interview.mp4\"\n",
        "video_cut = \"/content/drive/MyDrive/interview-cut.mp4\"\n",
        "video_out = \"/content/drive/MyDrive/interview-output.mp4\"\n",
        "output_csv = \"/content/drive/MyDrive/interview.csv\""
      ],
      "metadata": {
        "id": "tXa5ci4G_Ip_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize MediaPipe's Holistic module\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_holistic = mp.solutions.holistic\n",
        "holistic = mp_holistic.Holistic(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)"
      ],
      "metadata": {
        "id": "LhnDqMlzDP_N"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Functions"
      ],
      "metadata": {
        "id": "QN93ymPI-40M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clip input(.mp4) video to output(.mp4) video\n",
        "# start_time and end_time in seconds\n",
        "def extract_subclip(input, output, start_time, end_time):\n",
        "  ffmpeg_extract_subclip(input, start_time, end_time, targetname=output)"
      ],
      "metadata": {
        "id": "pYRjADBiAJSC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate the Euclidean distance between two points\n",
        "def euclidean_distance(p1, p2):\n",
        "    return np.sqrt((p1.x - p2.x) ** 2 + (p1.y - p2.y) ** 2)\n",
        "\n",
        "\n",
        "# Function to calculate the openness of a pose\n",
        "def pose_openness(holistic_landmarks):\n",
        "    keypoints = [\n",
        "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER],\n",
        "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER],\n",
        "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_HIP],\n",
        "        holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_HIP],\n",
        "    ]\n",
        "    \n",
        "    coords = np.array([(kp.x, kp.y) for kp in keypoints])\n",
        "    hull = ConvexHull(coords)\n",
        "    \n",
        "    return hull.volume\n",
        "\n",
        "\n",
        "# Function to calculate leaning direction\n",
        "def leaning_direction(holistic_landmarks):\n",
        "    nose = holistic_landmarks.landmark[mp_holistic.PoseLandmark.NOSE]\n",
        "    left_shoulder = holistic_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_SHOULDER]\n",
        "    right_shoulder = holistic_landmarks.landmark[mp_holistic.PoseLandmark.RIGHT_SHOULDER]\n",
        "    \n",
        "    avg_shoulder_z = (left_shoulder.z + right_shoulder.z) / 2\n",
        "\n",
        "    if nose.z < avg_shoulder_z:\n",
        "        return \"Forward\"\n",
        "    else:\n",
        "        return \"Backward\"\n",
        "\n",
        "\n",
        "# Function to calculate angle between three landmarks\n",
        "def calculate_angle(l1, l2, l3):\n",
        "\n",
        "    # Calculate the angle between the three points\n",
        "    angle = math.degrees(math.atan2(l3.y - l2.y, l3.x - l2.x) - math.atan2(l1.y - l2.y, l1.x - l2.x))\n",
        "    \n",
        "    # Check if the angle is less than zero.\n",
        "    if angle < 0:\n",
        "        # Add 360 to the found angle.\n",
        "        angle += 360\n",
        "  \n",
        "    return angle\n",
        "\n",
        "\n",
        "# Function to calculate angle between three landmarks using numpy module\n",
        "def numpy_angle(l1,l2,l3, width, height):\n",
        "  a = np.array([l1.x * width, l1.y * height])\n",
        "  b = np.array([l2.x * width, l2.y * height])\n",
        "  c = np.array([l3.x * width, l3.y * height])\n",
        "\n",
        "  ba = a - b\n",
        "  bc = c - b\n",
        "\n",
        "  cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
        "  angle = np.arccos(cosine_angle)\n",
        "\n",
        "  return np.degrees(angle)\n",
        "\n",
        "# Function to calculate hand orientation\n",
        "def orientation(l0, l9): \n",
        "    x0 = l0.x\n",
        "    y0 = l0.y\n",
        "    \n",
        "    x9 = l9.x\n",
        "    y9 = l9.y\n",
        "    \n",
        "    if abs(x9 - x0) < 0.05:      # since tan(0) --> ∞\n",
        "        m = 1000000000\n",
        "    else:\n",
        "        m = abs((y9 - y0)/(x9 - x0))       \n",
        "        \n",
        "    if m>=0 and m<=1:\n",
        "        if x9 > x0:\n",
        "            return \"Right\"\n",
        "        else:\n",
        "            return \"Left\"\n",
        "    if m>1:\n",
        "        if y9 < y0:       # since, y decreases upwards\n",
        "            return \"Up\"\n",
        "        else:\n",
        "            return \"Down\""
      ],
      "metadata": {
        "id": "1Jb8yGNaCO7I"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Variables"
      ],
      "metadata": {
        "id": "AGpzyv8_ExWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the cropped video(input)\n",
        "cap = cv2.VideoCapture(video_cut)\n",
        "\n",
        "# Get the video dimensions and FPS(input)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Initialize the VideoWriter(output)\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # You can also use \"XVID\" or \"MJPG\" for AVI files\n",
        "out = cv2.VideoWriter(video_out, fourcc, fps, (width, height))"
      ],
      "metadata": {
        "id": "LwEV3lf2FJkB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize variables \n",
        "\n",
        "PL = mp_holistic.PoseLandmark\n",
        "HL = mp_holistic.HandLandmark\n",
        "\n",
        "## Holistic\n",
        "prev_landmarks = None\n",
        "total_movement = 0\n",
        "holistic_threshold = 0.001  # Adjust the threshold to fine-tune movement detection sensitivity\n",
        "holistic_keypoints = [\n",
        "    mp_holistic.PoseLandmark.LEFT_WRIST,\n",
        "    mp_holistic.PoseLandmark.RIGHT_WRIST,\n",
        "    mp_holistic.PoseLandmark.LEFT_ANKLE,\n",
        "    mp_holistic.PoseLandmark.RIGHT_ANKLE,\n",
        "]\n",
        "\n",
        "## Arms\n",
        "left_arm_movement = 0\n",
        "right_arm_movement = 0\n",
        "\n",
        "la_counter = 0 \n",
        "la_vert = None\n",
        "la_leaning = None\n",
        "\n",
        "ra_counter = 0 \n",
        "ra_vert = None\n",
        "ra_leaning = None\n",
        "\n",
        "## Hand\n",
        "lh_stage = None\n",
        "lh_tip_distance = 0\n",
        "lh_orientation = None\n",
        "\n",
        "rh_stage = None\n",
        "rh_tip_distance = 0\n",
        "rh_orientation = None"
      ],
      "metadata": {
        "id": "hS6bWoCXHg5L"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract Data"
      ],
      "metadata": {
        "id": "BSAC0Z1xIoCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extract_subclip(video, video_cut, 0, 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w00QYtrHSF9D",
        "outputId": "dea90065-d2e9-4a20-859b-4f66dd521007"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Running:\n",
            ">>> \"+ \" \".join(cmd)\n",
            "Moviepy - Command successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open output CSV file and add header row\n",
        "with open(output_csv, mode='w', newline='') as csv_file:\n",
        "  writer = csv.writer(csv_file)\n",
        "  writer.writerow(['frame', 'total_movement', 'avg_pose_openness', 'leaning', 'left_arm_angle', 'left_arm_v_movement', 'left_arm_h_movement','right_arm_angle', 'right_arm_v_movement', 'right_arm_h_movement', 'left_hand_orientation', 'right_arm_state', 'right_hand_orientation', 'right_arm_state'])\n",
        "\n",
        "  # Process the video frames\n",
        "  count = 1\n",
        "  frame_number = 0\n",
        "\n",
        "  while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      break\n",
        "    \n",
        "    # process every fps's frame\n",
        "    if count % fps == 0:\n",
        "      # Convert the frame to RGB\n",
        "      frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      # Process the frame with MediaPipe's Holistic module\n",
        "      results = holistic.process(frame_rgb)\n",
        "\n",
        "      # Draw holistic landmarks on the frame\n",
        "      if results.pose_landmarks:\n",
        "        current = results.pose_landmarks\n",
        "        current_lh = results.left_hand_landmarks\n",
        "        current_rh = results.right_hand_landmarks\n",
        "\n",
        "        mp_drawing.draw_landmarks(frame, current, mp_holistic.POSE_CONNECTIONS)\n",
        "        mp_drawing.draw_landmarks(frame, current_lh, mp_holistic.HAND_CONNECTIONS)\n",
        "        mp_drawing.draw_landmarks(frame, current_rh, mp_holistic.HAND_CONNECTIONS)\n",
        "\n",
        "        ## Holistic movements\n",
        "        # Calculate the total movement\n",
        "        if prev_landmarks:\n",
        "          frame_movement = 0\n",
        "          for kp in holistic_keypoints:\n",
        "            distance = euclidean_distance(results.pose_landmarks.landmark[kp], prev_landmarks.landmark[kp])\n",
        "            frame_movement += distance\n",
        "          if frame_movement > holistic_threshold:\n",
        "            total_movement += frame_movement\n",
        "        \n",
        "        # Calculate and display the total movement and pose openness on the frame\n",
        "        openness_value = pose_openness(results.pose_landmarks)\n",
        "        # Calculate and display the leaning direction\n",
        "        leaning_dir = leaning_direction(results.pose_landmarks)\n",
        "\n",
        "        ## Hand movements\n",
        "        # distance b/w INDEX_FINGER_TIP and THUMB_TIP\n",
        "        if current_lh:\n",
        "          lh_tip_distance = euclidean_distance(current_lh.landmark[HL.INDEX_FINGER_TIP],current_lh.landmark[HL.THUMB_TIP])\n",
        "          if current_lh.landmark[HL.MIDDLE_FINGER_TIP].y < current_lh.landmark[HL.MIDDLE_FINGER_MCP].y and current_lh.landmark[HL.RING_FINGER_TIP].y < current_lh.landmark[HL.RING_FINGER_MCP].y \\\n",
        "            and current_lh.landmark[HL.PINKY_TIP].y < current_lh.landmark[HL.PINKY_TIP].y and lh_tip_distance < 0.015:\n",
        "            lh_stage = 'CLOSED'\n",
        "          else:\n",
        "            lh_stage = 'OPEN'\n",
        "          lh_orientation = orientation(current_lh.landmark[HL.WRIST], current_lh.landmark[HL.MIDDLE_FINGER_MCP])\n",
        "\n",
        "        if current_rh:\n",
        "          rh_tip_distance = euclidean_distance(current_rh.landmark[HL.INDEX_FINGER_TIP],current_rh.landmark[HL.THUMB_TIP])\n",
        "          if current_rh.landmark[HL.MIDDLE_FINGER_TIP].y < current_rh.landmark[HL.MIDDLE_FINGER_MCP].y and current_rh.landmark[HL.RING_FINGER_TIP].y < current_rh.landmark[HL.RING_FINGER_MCP].y \\\n",
        "            and current_rh.landmark[HL.PINKY_TIP].y < current_rh.landmark[HL.PINKY_TIP].y and rh_tip_distance < 0.015:\n",
        "            rh_stage = 'CLOSED'\n",
        "          else:\n",
        "            rh_stage = 'OPEN'\n",
        "          rh_orientation = orientation(current_rh.landmark[HL.WRIST], current_rh.landmark[HL.MIDDLE_FINGER_MCP])\n",
        "\n",
        "        ## Arm movements\n",
        "        # Calculate weather arm is up or down\n",
        "        la_angle = numpy_angle(current.landmark[PL.LEFT_WRIST], current.landmark[PL.LEFT_ELBOW], current.landmark[PL.LEFT_SHOULDER], width, height)\n",
        "        ra_angle = numpy_angle(current.landmark[PL.RIGHT_WRIST], current.landmark[PL.RIGHT_ELBOW], current.landmark[PL.RIGHT_SHOULDER], width, height)\n",
        "\n",
        "        if la_angle > 160:\n",
        "          la_vert = \"DOWN\"\n",
        "        if la_angle < 30 and la_vert =='DOWN':\n",
        "          la_vert=\"UP\"\n",
        "          la_counter +=1\n",
        "\n",
        "        if ra_angle > 160:\n",
        "          ra_vert = \"DOWN\"\n",
        "        if ra_angle < 30 and ra_vert =='DOWN':\n",
        "          ra_vert=\"UP\"\n",
        "          ra_counter +=1\n",
        "\n",
        "        # Calculate wheather arm is leaning forward\n",
        "        if abs(current.landmark[PL.RIGHT_WRIST].z) > abs(current.landmark[PL.RIGHT_ELBOW].z):\n",
        "          ra_leaning = 'FORWARD'\n",
        "        else:\n",
        "          ra_leaning = 'CALCULATING'\n",
        "\n",
        "        if abs(current.landmark[PL.LEFT_WRIST].z) > abs(current.landmark[PL.LEFT_ELBOW].z) :\n",
        "          la_leaning = 'FORWARD'\n",
        "        else:\n",
        "          la_leaning = 'CALCULATING'\n",
        "        \n",
        "        # write to output csv\n",
        "        writer.writerow([count, total_movement, openness_value, leaning_dir, la_angle, la_vert, la_leaning, ra_angle, ra_vert, ra_leaning, lh_orientation, lh_stage, rh_orientation, rh_stage])\n",
        "\n",
        "        # write to output video\n",
        "        l1 = current.landmark[PL.LEFT_SHOULDER]\n",
        "        l2 = current.landmark[PL.LEFT_ELBOW]\n",
        "        l3 = current.landmark[PL.LEFT_WRIST]\n",
        "        r1 = current.landmark[PL.RIGHT_SHOULDER]\n",
        "        r2 = current.landmark[PL.RIGHT_ELBOW]\n",
        "        r3 = current.landmark[PL.RIGHT_WRIST]\n",
        "        \n",
        "        cv2.putText(frame, f\"Left shoulder:({round(l1.x,2)}, {round(l1.y,2)}, {round(l1.z,2)}) elbow:({round(l2.x,2)}, {round(l2.y,2)}, {round(l2.z,2)}) wrist: ({round(l3.x,2)}, {round(l3.y,2)}, {round(l3.z,2)})\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Left arm: {la_vert}  {la_leaning}\", (10,60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Left arm angle: {la_angle:.2f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "        cv2.putText(frame, f\"Right shoulder:({round(r1.x,2)}, {round(r1.y,2)}, {round(r1.z,2)}) elbow:({round(r2.x,2)}, {round(r2.y,2)}, {round(r2.z,2)}) wrist: ({round(r3.x,2)}, {round(r3.y,2)}, {round(r3.z,2)})\", (10,120), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Right arm: {ra_vert}  {ra_leaning}\", (10,150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Right arm angle: {ra_angle:.4f}\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
        "\n",
        "        cv2.putText(frame, f\"Left Hand: {lh_tip_distance} {lh_stage} {lh_orientation}\", (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Right Hand: {rh_tip_distance} {rh_stage} {rh_orientation}\", (10, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)\n",
        "\n",
        "        # update variables\n",
        "        prev_landmarks = results.pose_landmarks\n",
        "        frame_number += 1\n",
        "\n",
        "    # Save the frame\n",
        "    count = count + 1\n",
        "    out.write(frame)\n",
        "\n",
        "  out.release()"
      ],
      "metadata": {
        "id": "AvDOHaVqIqLo"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}